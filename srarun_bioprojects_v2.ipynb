{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/workspace/.mwas/lib/python3.9/site-packages (from requests) (2023.11.17)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary\n",
    "%pip install pandas\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.sax\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store full mapping between BioProjectID and BioSampleID\n",
    "bioproject_mapping_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Generating BioSample to BioProject mapping\n",
    "- complete mapping from BioSampleID to BioProjectID does not exist in NCBI\n",
    "- can be extracted from 3 separate locations:\n",
    "    - BioProject XML file\n",
    "    - BioSample XML file\n",
    "    - SRA BigQuery metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated mapping folder here when re-running the notebook\n",
    "mapping_folder = 'pickles/v1.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioProject XML\n",
    "- Some BioProject XMLs store the BioSampleIDs of their associated BioSamples\n",
    "    - ```<Package>``` tag contains a single BioProject\n",
    "    - ```<ArchiveID>``` contains the BioProject ID\n",
    "    - ```<LocusTagPrefix biosample_id=''>``` contains the BioSample IDs associated with the BioProject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickled dictionary from disk\n"
     ]
    }
   ],
   "source": [
    "bioproject_mapping_dict_1 = {}\n",
    "bioproject_xml_path = \"/home/ec2-user/workspace/data/bioproject.xml\"\n",
    "\n",
    "class BioProjectParser(xml.sax.ContentHandler):\n",
    "    '''\n",
    "    SAX parser to extract BioSample IDs from a BioProject XML file.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, project_dict):\n",
    "        self.biosample_ids = []\n",
    "        self.bioproject_id= \"\"\n",
    "        self.project_dict = project_dict\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == \"ArchiveID\":\n",
    "            self.bioproject_id = attrs[\"accession\"]\n",
    "        elif name == \"LocusTagPrefix\":\n",
    "            if \"biosample_id\" in attrs:\n",
    "                self.biosample_ids.append(attrs[\"biosample_id\"])\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == \"Package\":\n",
    "            self.project_dict[self.bioproject_id] = self.biosample_ids\n",
    "            self.bioproject_id = \"\"\n",
    "            self.biosample_ids = []\n",
    "\n",
    "\n",
    "# Try to read the pickled dictionary from disk\n",
    "try:\n",
    "    with open(f\"{mapping_folder}/bioproject_mapping_dict_1.pickle\", \"rb\") as f:\n",
    "        bioproject_mapping_dict_1 = pickle.load(f)\n",
    "    print(\"Loaded pickled dictionary from disk\")\n",
    "except:\n",
    "    print(\"No pickled dictionary found, parsing XML\")\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(BioProjectParser(bioproject_mapping_dict_1))\n",
    "    parser.parse(bioproject_xml_path)\n",
    "\n",
    "    with open(f\"{mapping_folder}/bioproject_mapping_dict_1.pickle\", \"wb\") as f:\n",
    "        pickle.dump(bioproject_mapping_dict_1, f)\n",
    "\n",
    "    print(\"Pickled dictionary to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1: \n",
      "Number of BioProjects: 822292\n",
      "Number of mapped BioSamples: 2717532\n",
      "Number of unique BioSamples: 2601705\n"
     ]
    }
   ],
   "source": [
    "print('Stage 1: ')\n",
    "print(f'Number of BioProjects: {len(bioproject_mapping_dict_1)}')\n",
    "print(f'Number of mapped BioSamples: {sum([len(v) for v in bioproject_mapping_dict_1.values()])}')\n",
    "print(f'Number of unique BioSamples: {len(set([item for sublist in bioproject_mapping_dict_1.values() for item in sublist]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SRA metadata only has 451347 unique BioProjects, BioProject XML should not have more than this\n",
    "    - likely have BioProjects that have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioSample XML\n",
    "- some BioSample records contain entrez links to the corresponding BioProject (17,700,598 / 37,158,431)\n",
    "    - small number contain just the uid of the BioProject (17,541 / 17,700,598)\n",
    "        - cannot be used reliably since complete ID can be PRJ(NA/EB/DB)\n",
    "    - majority of containing records have the full BioProjectID (17,683,057 / 17,700,598)\n",
    "        - stored under the `label` attribute of the `Link` tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickled dictionary from disk\n"
     ]
    }
   ],
   "source": [
    "bioproject_mapping_dict_2 = {}\n",
    "biosample_xml_path = \"/home/ec2-user/workspace/data/biosample_set.xml\"\n",
    "\n",
    "class BioSampleParser(xml.sax.ContentHandler):\n",
    "    '''\n",
    "    SAX parser to extract BioProject IDs from a BioSample XML file.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, project_dict):\n",
    "        self.bioproject_ids = []\n",
    "        self.biosample_id= \"\"\n",
    "        self.project_dict = project_dict\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == 'BioSample':\n",
    "            self.biosample_id = attrs['accession']\n",
    "        elif name == 'Link':\n",
    "            # check if the link is to a BioProject and extract the ID if possible\n",
    "            isBioproject = 'target' in attrs and attrs['target'] == 'bioproject'\n",
    "            hasLabel = 'label' in attrs\n",
    "            if isBioproject and hasLabel:\n",
    "                self.bioproject_ids.append(attrs['label'])\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if name == \"BioSample\":\n",
    "            for bioproject_id in self.bioproject_ids:\n",
    "                # append or add to the dictionary\n",
    "                if bioproject_id in self.project_dict:\n",
    "                    self.project_dict[bioproject_id].append(self.biosample_id)\n",
    "                else:\n",
    "                    self.project_dict[bioproject_id] = [self.biosample_id]\n",
    "            self.bioproject_ids = []\n",
    "            self.biosample_id = \"\"\n",
    "\n",
    "# Try to read the pickled dictionary from disk\n",
    "try:\n",
    "    with open(f\"{mapping_folder}/bioproject_mapping_dict_2.pickle\", \"rb\") as f:\n",
    "        bioproject_mapping_dict_2 = pickle.load(f)\n",
    "    print(\"Loaded pickled dictionary from disk\")\n",
    "except:\n",
    "    print(\"No pickled dictionary found, parsing XML\")\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(BioSampleParser(bioproject_mapping_dict_2))\n",
    "    parser.parse(biosample_xml_path)\n",
    "\n",
    "    with open(f'{mapping_folder}/bioproject_mapping_dict_2.pickle', 'wb') as f:\n",
    "        pickle.dump(bioproject_mapping_dict_2, f)\n",
    "\n",
    "    print(\"Pickled dictionary to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2: \n",
      "Number of BioProjects: 468882\n",
      "Number of mapped BioSamples: 18873209\n",
      "Number of unique BioSamples: 18758458\n"
     ]
    }
   ],
   "source": [
    "print('Stage 2: ')\n",
    "print(f'Number of BioProjects: {len(bioproject_mapping_dict_2)}')\n",
    "print(f'Number of mapped BioSamples: {sum([len(v) for v in bioproject_mapping_dict_2.values()])}')\n",
    "print(f'Number of unique BioSamples: {len(set([item for sublist in bioproject_mapping_dict_2.values() for item in sublist]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRA BigQuery metadata\n",
    "- BigQuery table contains metadata for all runs in the SRA\n",
    "    - table downloaded on 2024-01-23\n",
    "- database queried for SRA accession, BioSampleID, and BioProjectID:\n",
    "    - `` SELECT acc, biosample, bioproject FROM `nih-sra-datastore.sra.metadata` ``\n",
    "    - downloaded as two separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cp data/sra_metadata_bp_map_1.csv data/sra_metadata_bp_map.csv\n",
    "tail -n +2 data/sra_metadata_bp_map_2.csv >> data/sra_metadata_bp_map.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pickled dictionary from disk\n"
     ]
    }
   ],
   "source": [
    "# iterate through the file and add all mappings to a dictionary\n",
    "bioproject_mapping_dict_3 = {}\n",
    "sra_metadata_bp_map_path = \"/home/ec2-user/workspace/mwas/data/sra_metadata_bp_map.csv\"\n",
    "\n",
    "try:\n",
    "    with open(f\"{mapping_folder}/bioproject_mapping_dict_3.pickle\", \"rb\") as f:\n",
    "        bioproject_mapping_dict_3 = pickle.load(f)\n",
    "    print(\"Loaded pickled dictionary from disk\")\n",
    "except:\n",
    "    df = pd.read_csv(sra_metadata_bp_map_path)\n",
    "    # remove any null values as we cannot any mapping from them\n",
    "    df = df.dropna()\n",
    "\n",
    "    def get_mapping(row):\n",
    "        # helper function to extract the biosample to bioproject mapping\n",
    "        bioproject_id = row['bioproject']\n",
    "        biosample_id = row['biosample']\n",
    "\n",
    "        if bioproject_id in bioproject_mapping_dict_3:\n",
    "            bioproject_mapping_dict_3[bioproject_id].append(biosample_id)\n",
    "        else:\n",
    "            bioproject_mapping_dict_3[bioproject_id] = [biosample_id]\n",
    "\n",
    "    df.apply(get_mapping, axis=1)\n",
    "\n",
    "    # pickle the output\n",
    "    with open(f'{mapping_folder}/bioproject_mapping_dict_3.pickle', 'wb') as f:\n",
    "        pickle.dump(bioproject_mapping_dict_3, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 3: \n",
      "Number of BioProjects: 450725\n",
      "Number of mapped BioSamples: 31130322\n",
      "Number of unique BioSamples: 21031084\n"
     ]
    }
   ],
   "source": [
    "print('Stage 3: ')\n",
    "print(f'Number of BioProjects: {len(bioproject_mapping_dict_3)}')\n",
    "print(f'Number of mapped BioSamples: {sum([len(v) for v in bioproject_mapping_dict_3.values()])}')\n",
    "print(f'Number of unique BioSamples: {len(set([item for sublist in bioproject_mapping_dict_3.values() for item in sublist]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique BioProject Ids from bioproject.xml: 822292\n",
      "Unique BioProject Ids from sra metadata: 450725\n",
      "\n",
      "Number of Ids in the xml but not the metadata: 372204\n",
      "Number of Ids in the metadata but not the xml: 637\n"
     ]
    }
   ],
   "source": [
    "# check for bioprojects that are in bioproject xml but not the SRA metadata\n",
    "bp_xml_ids = set(bioproject_mapping_dict_1)\n",
    "print(f'Unique BioProject Ids from bioproject.xml: {len(bp_xml_ids)}')  \n",
    "\n",
    "sra_metadata_ids = set(bioproject_mapping_dict_3)\n",
    "print(f'Unique BioProject Ids from sra metadata: {len(sra_metadata_ids)}\\n') \n",
    "\n",
    "print(f'Number of Ids in the xml but not the metadata: {len(bp_xml_ids - sra_metadata_ids)}')\n",
    "print(f'Number of Ids in the metadata but not the xml: {len(sra_metadata_ids - bp_xml_ids)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- want to merge all three sources to get as complete a mapping as possible\n",
    "- merged dictionary should have same BioProject to BioSample structure\n",
    "    - can be unwrapped and written to csv for parsing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(f\"{mapping_folder}/bioproject_mapping_dict.pickle\", \"rb\") as f:\n",
    "        bioproject_mapping_dict = pickle.load(f)\n",
    "    print(\"Loaded pickled dictionary from disk\")\n",
    "except:\n",
    "    # add everything to bioproject_mapping_dict \n",
    "    for bioproject_id, biosample_list in bioproject_mapping_dict_1.items():\n",
    "        if bioproject_id in bioproject_mapping_dict:\n",
    "            bioproject_mapping_dict[bioproject_id].update(set(biosample_list))\n",
    "        else:\n",
    "            bioproject_mapping_dict[bioproject_id] = set(biosample_list)\n",
    "\n",
    "    for bioproject_id, biosample_list in bioproject_mapping_dict_2.items():\n",
    "        if bioproject_id in bioproject_mapping_dict:\n",
    "            bioproject_mapping_dict[bioproject_id].update(set(biosample_list))\n",
    "        else:\n",
    "            bioproject_mapping_dict[bioproject_id] = set(biosample_list)\n",
    "\n",
    "    for bioproject_id, biosample_list in bioproject_mapping_dict_3.items():\n",
    "        if bioproject_id in bioproject_mapping_dict:\n",
    "            bioproject_mapping_dict[bioproject_id].update(set(biosample_list))\n",
    "        else:\n",
    "            bioproject_mapping_dict[bioproject_id] = set(biosample_list)\n",
    "\n",
    "    with open(f'{mapping_folder}/bioproject_mapping_dict.pickle', 'wb') as f:\n",
    "        pickle.dump(bioproject_mapping_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total BioProject mapping stats: \n",
      "Number of BioProjects: 825023\n",
      "Number of mapped BioSamples: 27251791\n",
      "Number of unique BioSamples: 21031084\n"
     ]
    }
   ],
   "source": [
    "print('Total BioProject mapping stats: ')\n",
    "print(f'Number of BioProjects: {len(bioproject_mapping_dict)}')\n",
    "print(f'Number of mapped BioSamples: {sum([len(v) for v in bioproject_mapping_dict.values()])}')\n",
    "print(f'Number of unique BioSamples: {len(set([item for sublist in bioproject_mapping_dict_3.values() for item in sublist]))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Merging BioSample csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import re\n",
    "bioproject_ids = ['PRJNA338276']\n",
    "bioproject_mapping_dict['PRJNA338276']\n",
    "\n",
    "# connect to s3\n",
    "s3 = boto3.resource(\"s3\")\n",
    "bucket = s3.Bucket('serratus-biosamples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quote_preprocess(data):\n",
    "    # helper function to preprocess quotation marks for a csv string\n",
    "    # fist check if the data is not null\n",
    "    try:\n",
    "        # escape all quotes\n",
    "        return re.sub(r'[\"]', '\"\"', data)\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "\n",
    "bioproject_data = []\n",
    "col_set = set()\n",
    "\n",
    "for biosample_id in bioproject_mapping_dict[bioproject_ids[0]]:\n",
    "    key = f\"biosamples_csv/{biosample_id}.csv\"\n",
    "    try:\n",
    "        obj = bucket.Object(key).get()[\"Body\"]#.read().decode(\"utf-8\")#.split(\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    # convert to a dataframe\n",
    "    df = pd.read_csv(obj)\n",
    "    df = df.map(apply_quote_preprocess) # add proper escaping around all quotes\n",
    "    # convert to a dictionary\n",
    "    bioproject_dict = df.to_dict(orient='list') # can orient as list since the csvs are each 1 row\n",
    "\n",
    "    # add the columns to the set\n",
    "    col_set.update(bioproject_dict.keys())\n",
    "    # add the dictionary to the list\n",
    "    bioproject_data.append(bioproject_dict)\n",
    "\n",
    "# generate a csv string from the data\n",
    "csv_str = ','.join(col_set) + '\\n'\n",
    "for row in bioproject_data:\n",
    "    csv_str += ','.join([f'\"{row[col][0]}\"' if col in row else '' for col in col_set]) + '\\n'\n",
    "\n",
    "# write the csv string to a file\n",
    "with open('bioproject_data.csv', 'w') as f:\n",
    "    f.write(csv_str)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
